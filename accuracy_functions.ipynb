{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "2b2e7e96bc9272e10b8dacfa083a630c9ae5968c"
   },
   "outputs": [],
   "source": [
    "#### Accuracy functions ####\n",
    "\n",
    "# Function to normalize a single image\n",
    "def normalize_2(x):\n",
    "    # Input: [1, height, width]\n",
    "    x_shape = x.shape\n",
    "    x = x.view(1,-1)\n",
    "    x = x - torch.min(x)\n",
    "    x = x / (torch.max(x) + 1e-8)\n",
    "    if torch.sum(torch.isnan(x))>0:\n",
    "        print(\"nan of tmp\",torch.sum(torch.isnan(x)))\n",
    "    return x.view(x_shape)\n",
    "\n",
    "# Function to calculate balanced accuracy\n",
    "def balanced_accuracy( logits, y_hot, Do_print=None):\n",
    "    # Input:\n",
    "    # logits: [batch_size, num_samples, no_classes]\n",
    "    # y_hot: [batch_size, num_samples, no_classes]\n",
    "    \n",
    "    logits = logits.cpu().detach()\n",
    "    y_hot = y_hot.cpu().detach()\n",
    "    \n",
    "    logits = logits.view(-1,2)\n",
    "    y_hot = y_hot.view(-1,2)\n",
    "    \n",
    "    TP = torch.sum(y_hot[:,0]*torch.round(logits[:,0]))   # True posistive\n",
    "    FP = torch.sum(y_hot[:,1]*torch.round(logits[:,0]))   # False positive\n",
    "    FN = torch.sum(y_hot[:,0]*torch.round(logits[:,1]))   # False negative\n",
    "    TN = torch.sum(y_hot[:,1]*torch.round(logits[:,1]))   # True negative\n",
    "\n",
    "    P = TP + FN\n",
    "    N = FP + TN\n",
    "    \n",
    "    if Do_print != None:\n",
    "        print(\"TP: \",TP)\n",
    "        print(\"FP: \",FP)\n",
    "        print(\"TN: \",TN)\n",
    "        print(\"FN: \",FN)\n",
    "        print(\"P: \",P)\n",
    "        print(\"N: \",N)\n",
    "\n",
    "    acc = torch.sum(TP/P + TN/N)/2\n",
    "        \n",
    "    return acc\n",
    "\n",
    "# Function to calculate balanced binary crossentropy\n",
    "def balanced_binary_cross_entropy( logits, y_hot):\n",
    "    # Input:\n",
    "    # logits: [batch_size, num_samples, no_classes]\n",
    "    # y_hot: [batch_size, num_samples, no_classes]\n",
    "    \n",
    "    if cuda:\n",
    "        classWeight = torch.FloatTensor([torch.sum(y_hot[:,1,0])/torch.sum(y_hot[:,1,]),\\\n",
    "                                     torch.sum(y_hot[:,1,1])/torch.sum(y_hot[:,1,])]).cuda(device=0)\n",
    "    else:\n",
    "        classWeight = torch.FloatTensor([torch.sum(y_hot[:,1,0])/torch.sum(y_hot[:,1,]),\\\n",
    "                                     torch.sum(y_hot[:,1,1])/torch.sum(y_hot[:,1,])])\n",
    "        \n",
    "    class_loss_0 = 0\n",
    "    class_loss_1 = 0\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        tmp = torch.mean(y_hot, dim = 1)[i][0] \n",
    "        if tmp == 0:\n",
    "            class_loss_0 += torch.nn.functional.binary_cross_entropy(logits[i], y_hot[i])\n",
    "        else:\n",
    "            class_loss_1 += torch.nn.functional.binary_cross_entropy(logits[i], y_hot[i])\n",
    "        \n",
    "    #bal_binary_cross_entropy = classWeight[0]*class_loss_0 + classWeight[1]*class_loss_1\n",
    "    bal_binary_cross_entropy = (0.5/classWeight[0])*class_loss_0 + (0.5/classWeight[1])*class_loss_1\n",
    "        \n",
    "    return bal_binary_cross_entropy/batch_size\n",
    "\n",
    "def balanced_accuracy_test( logits, y_hot, Do_print=None):\n",
    "    # Input:\n",
    "    # logits: [batch_size, num_samples, no_classes]\n",
    "    # y_hot: [batch_size, num_samples, no_classes]\n",
    "    \n",
    "    logits = logits.cpu().detach()\n",
    "    y_hot = y_hot.cpu().detach()\n",
    "    \n",
    "    logits = logits.view(-1,2)\n",
    "    y_hot = y_hot.view(-1,2)\n",
    "    \n",
    "    TP = torch.sum(y_hot[:,0]*torch.round(logits[:,0]))   # True posistive\n",
    "    FP = torch.sum(y_hot[:,1]*torch.round(logits[:,0]))   # False positive\n",
    "    FN = torch.sum(y_hot[:,0]*torch.round(logits[:,1]))   # False negative\n",
    "    TN = torch.sum(y_hot[:,1]*torch.round(logits[:,1]))   # True negative\n",
    "\n",
    "    P = TP + FN\n",
    "    N = FP + TN\n",
    "    \n",
    "    if Do_print != None:\n",
    "        print(\"TP: \",TP)\n",
    "        print(\"FP: \",FP)\n",
    "        print(\"TN: \",TN)\n",
    "        print(\"FN: \",FN)\n",
    "        print(\"P: \",P)\n",
    "        print(\"N: \",N)\n",
    "\n",
    "    acc = torch.sum(TP/P + TN/N)/2\n",
    "        \n",
    "    return acc, TP, FP, FN, TN, P, N"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
