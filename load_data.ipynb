{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging( i, print_every, no_samples, tic, elapsed_time):\n",
    "    \"\"\"\n",
    "    Function for logging: timing and counting\n",
    "    Inputs:\n",
    "    - i:            Iteration i \n",
    "    - print_every:  Print logging in the interval of print_every\n",
    "    - no_samples:   Number of samples\n",
    "    - tic:          Start timer for last time\n",
    "    - elapsed_time: Amount of time elapsed \n",
    "    \"\"\"\n",
    "    if not i % print_every:\n",
    "        toc = time.clock()\n",
    "        period_time = toc - tic;\n",
    "        if i > 0:\n",
    "            elapsed_time = (elapsed_time + period_time)\n",
    "            mean_period_time = elapsed_time/ ((i)/print_every)\n",
    "            minutes = round(mean_period_time*( (No_samples_train-i)//print_every)//60)\n",
    "            seconds = round(mean_period_time*( (No_samples_train-i)/print_every)%60)\n",
    "            print(\"Data loaded:\", i,\"/\",No_samples_train,  \"    Remaining time: \", minutes,\":\", seconds)\n",
    "        tic = time.clock(); \n",
    "    else:\n",
    "        tic = -1\n",
    "        elapsed_time = -1\n",
    "    return tic, elapsed_time\n",
    "\n",
    "\n",
    "def uniform_stratified_sampler(labels, n=None):\n",
    "    \"\"\"\n",
    "    Stratified sampler that distributes labels uniformly by\n",
    "    sampling at most n data points per class\n",
    "    \"\"\"\n",
    "    from functools import reduce\n",
    "    # Only choose digits in n_labels\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "\n",
    "    # Ensure uniform distribution of labels\n",
    "    np.random.shuffle(indices)\n",
    "    indices = np.hstack([list(filter(lambda idx: labels[idx] == i, indices))[:n] for i in classes])\n",
    "\n",
    "    indices = torch.from_numpy(indices)\n",
    "    sampler = SubsetRandomSampler(indices)\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def construct_DataLoader( Target, Image, batch_size, labels_per_class=None):\n",
    "    \"\"\"\n",
    "    Contruct DataLoader with tensors\n",
    "    Inputs:\n",
    "    - Target:            Iteration i \n",
    "    - Image:  Print logging in the interval of print_every\n",
    "    - batch_size\n",
    "    \"\"\"\n",
    "    # Convert to Tensor\n",
    "    Target = torch.Tensor(Target)\n",
    "    Image = torch.Tensor(Image)\n",
    "    Image = Image.unsqueeze(1)\n",
    "\n",
    "    # Construct DataLoader\n",
    "    loader = TensorDataset(Image, Target)\n",
    "    if labels_per_class==None:\n",
    "        dataLoader = DataLoader(loader, batch_size=batch_size, shuffle = True)\n",
    "    else:    \n",
    "        dataLoader = DataLoader(loader, batch_size=batch_size,\n",
    "                     sampler=uniform_stratified_sampler(Target, labels_per_class))\n",
    "    return dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patientId    00436515-870c-4b36-a041-de91049b9ab4\n",
      "x                                             264\n",
      "y                                             152\n",
      "width                                         213\n",
      "height                                        379\n",
      "Target                                          1\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "######### Defining the data set #########\n",
    "\n",
    "KAGGLE = False\n",
    " \n",
    "# Display label format\n",
    "if KAGGLE:\n",
    "    df = pd.read_csv('../input/stage_2_detailed_class_info.csv')\n",
    "    df.rename(columns={'class': 'Target'}, inplace=True)\n",
    "    mapping = {'Normal': 0, 'Lung Opacity': 1, 'No Lung Opacity / Not Normal': 2}\n",
    "    df = df.replace({'Target': mapping})\n",
    "    df = df[ df['Target']!=2 ]\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    df = pd.read_csv('data/stage_1_train_labels.csv')\n",
    "\n",
    "\"\"\"\n",
    "# Defining the size of the data set\n",
    "classes = [0,1]          # ['Normal , 'Lung Opacity']  \n",
    "batch_size       = 64\n",
    "labels_per_class = 32    # Specify how many labelled examples we want per class\n",
    "No_samples_train_labelled = labels_per_class*len(classes)\n",
    "No_samples_train = 64\n",
    "No_samples_test  = 64\n",
    "IMG_SIZE         = 32\n",
    "img_dimension = [IMG_SIZE,IMG_SIZE]\n",
    "\"\"\"\n",
    "\n",
    "# Test connection to data set\n",
    "No = 4\n",
    "patientId = df['patientId'][No]\n",
    "if KAGGLE:\n",
    "    dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId\n",
    "else:\n",
    "    dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId\n",
    "dcm_data = pydicom.read_file(dcm_file)\n",
    "print(\"Connection to dataset established:\")\n",
    "print(df.iloc[No])\n",
    "print(' ')\n",
    "\n",
    "# Get only unique entrances from the provided data (some patients occur multiple times)\n",
    "unq, idx = np.unique(df['patientId'], return_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "3f518499954d2ad60289c06138d796a17a6f5aee",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images: 0 / 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 10 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 20 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 30 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 40 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 50 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 60 / 64     Remaining time:  0 : 0\n",
      "Train data loaded: 64\n",
      " \n",
      "Data loaded: 10 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 20 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 30 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 40 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 50 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 60 / 64     Remaining time:  0 : 0\n",
      "Test data loaded: 64\n",
      " \n",
      "Data loaded: 10 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 20 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 30 / 64     Remaining time:  0 : 1\n",
      "Data loaded: 40 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 50 / 64     Remaining time:  0 : 0\n",
      "Data loaded: 60 / 64     Remaining time:  0 : 0\n",
      "Labelled data loaded: 87\n"
     ]
    }
   ],
   "source": [
    "######### Load data into DataLoader's #########\n",
    "# Load unlabelled training data\n",
    "# Load labelled test data\n",
    "# Load labelled training data\n",
    "\n",
    "\"\"\"\n",
    "print_every = 10\n",
    "\"\"\"\n",
    "Do_img_eq = True\n",
    "\n",
    "######### Loading UNLABELED TRAINING data #########\n",
    "Target = []; Image = []\n",
    "tic = time.clock(); elapsed_time = 0\n",
    "\n",
    "print(\"Loading training images: 0 /\", No_samples_train)\n",
    "for i in range(0,No_samples_train):\n",
    "    Target.append(df.Target[idx[i]]) # Get label  \n",
    "    patientId = df['patientId'][idx[i]] # Get patient id from the idx \n",
    "    if KAGGLE:\n",
    "        dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    else:\n",
    "        dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    dcm_data = pydicom.read_file(dcm_file) # Load the image \n",
    "    Image.append(resize(dcm_data.pixel_array, output_shape=img_dimension, mode='reflect'))#, anti_aliasing=True)) # resize image\n",
    "    if Do_img_eq:\n",
    "        Image[-1] = equalize_hist(Image[-1])\n",
    "    \n",
    "    # Logging: counting and time remaining\n",
    "    val1, val2 = logging(i, print_every, No_samples_train, tic, elapsed_time)\n",
    "    if not val1 == -1:\n",
    "        tic = val1\n",
    "        elapsed_time = val2    \n",
    "    i = i + 1\n",
    "    \n",
    "print(\"Train data loaded:\", i)\n",
    "train_loader = construct_DataLoader( Target, Image, batch_size)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "######### Loading TEST data #########\n",
    "Target = []; Image = []\n",
    "tic = time.clock(); elapsed_time = 0\n",
    "for i in range(0,No_samples_test):\n",
    "    Target.append(df.Target[idx[No_samples_train+i]]) # Get label  \n",
    "    patientId = df['patientId'][idx[No_samples_train+i]] # Get patient id from the idx \n",
    "    if KAGGLE:\n",
    "        dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    else:\n",
    "        dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    dcm_data = pydicom.read_file(dcm_file) # Load the image \n",
    "    Image.append(resize(dcm_data.pixel_array, output_shape=img_dimension, mode='reflect'))#, anti_aliasing=True)) # resize image\n",
    "    if Do_img_eq:\n",
    "        Image[-1] = equalize_hist(Image[-1])\n",
    "        \n",
    "    # Logging: counting and time remaining\n",
    "    val1, val2 = logging(i, print_every, No_samples_test, tic, elapsed_time)\n",
    "    if not val1 == -1:\n",
    "        tic = val1\n",
    "        elapsed_time = val2\n",
    "    i = i + 1\n",
    "    \n",
    "print(\"Test data loaded:\", i)\n",
    "test_loader = construct_DataLoader( Target, Image, batch_size)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "######### Loading LABELED TRAINING data #########\n",
    "Target = []; Image = []\n",
    "tic = time.clock(); elapsed_time = 0\n",
    "count_unlabelled = 0; count_labelled = 0\n",
    "count_old = 0;\n",
    "i = 0\n",
    "while count_labelled<labels_per_class or count_unlabelled<labels_per_class:\n",
    "    Target.append(df.Target[idx[No_samples_test+No_samples_train+i]]) # Get label  \n",
    "\n",
    "    if Target[i]==1:\n",
    "        count_labelled = count_labelled + 1\n",
    "    else:\n",
    "        count_unlabelled = count_unlabelled + 1\n",
    "        \n",
    "    patientId = df['patientId'][idx[No_samples_test+No_samples_train+i]] # Get patient id from the idx \n",
    "    if KAGGLE:\n",
    "        dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    else:\n",
    "        dcm_file = 'data/stage_1_train_images/%s.dcm' % patientId # find the image-file corresponding to the patient id\n",
    "    dcm_data = pydicom.read_file(dcm_file) # Load the image \n",
    "    Image.append(resize(dcm_data.pixel_array, output_shape=img_dimension, mode='reflect'))#, anti_aliasing=True)) # resize image\n",
    "    if Do_img_eq:\n",
    "        Image[-1] = equalize_hist(Image[-1])\n",
    "\n",
    "    # Logging: counting and time remaining\n",
    "    count = min(count_labelled, count_unlabelled)\n",
    "    if (count > count_old):\n",
    "        count_old = min(count_labelled, count_unlabelled)\n",
    "        val1, val2 = logging(2*count, print_every, No_samples_train_labelled, tic, elapsed_time)\n",
    "        if not val1 == -1:\n",
    "            tic = val1\n",
    "            elapsed_time = val2  \n",
    "    i = i + 1\n",
    "\n",
    "print(\"Labelled data loaded:\", No_samples_train_labelled)\n",
    "train_loader_labelled = construct_DataLoader( Target, Image, batch_size, labels_per_class)\n",
    "\n",
    "del df, idx, unq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
